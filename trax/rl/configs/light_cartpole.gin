# Copyright 2020 The Trax Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import trax.lr_schedules
import trax.models
import trax.optimizers
import trax.rl

# Parameters for MLP:
# ==============================================================================
MLP.d_hidden = 64
MLP.n_hidden_layers = 1
MLP.n_output_classes = 2
MLP.flatten = False

# Parameters for MultifactorSchedule:
# ==============================================================================
MultifactorSchedule.constant = 0.01
MultifactorSchedule.factors = 'constant'

# Parameters for RLTask:
# ==============================================================================
RLTask.env = "CartPole-v0"
RLTask.initial_trajectories = 1
RLTask.gamma = 0.9
RLTask.max_steps = 200

# Parameters for PolicyGradientTrainer:
# ==============================================================================
PolicyGradientTrainer.model = @trax.models.MLP
PolicyGradientTrainer.optimizer = @trax.optimizers.Adam
PolicyGradientTrainer.batch_size = 128
PolicyGradientTrainer.train_steps_per_epoch = 1
PolicyGradientTrainer.collect_per_epoch = 1
PolicyGradientTrainer.max_slice_length = 1

# Parameters for train_rl:
# ==============================================================================
train_rl.light_rl = True
train_rl.light_rl_trainer = @trax.rl.PolicyGradientTrainer
train_rl.n_epochs = 200
